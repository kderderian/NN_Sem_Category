{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = image.load_img(\"Multicategory_Both_8/training/cat/A.jpg\")\n",
    "#plt.imshow(img)\n",
    "#cv2.imread(\"Multicategory_Both_8/training/cat/A.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change range to -0.5 to 0.5?\n",
    "train = ImageDataGenerator(rescale = 1/255)\n",
    "validation = ImageDataGenerator(rescale = 1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 images belonging to 8 classes.\n",
      "Found 29 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#Validation dataset not being used...what to do with test dataset?\n",
    "train_dataset = train.flow_from_directory('Multicategory_Both_8/training',\n",
    "                                         target_size = (200,200), \n",
    "                                         batch_size = 8, #this  should match # of categories\n",
    "                                         class_mode = 'categorical')\n",
    "validation_dataset = train.flow_from_directory('Multicategory_Both_8/validation',\n",
    "                                         target_size = (200,200), \n",
    "                                         batch_size = 8, \n",
    "                                         class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(16,(3,3),activation = 'relu', input_shape = (200,200,3)),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    #\n",
    "                                    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    #\n",
    "                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "                                    tf.keras.layers.MaxPool2D(2,2),\n",
    "                                    ##\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    ##\n",
    "                                    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "                                    ##\n",
    "                                    tf.keras.layers.Dense(8, activation = 'sigmoid') #to allow independent decisions for each category                                                     \n",
    "                                    ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = RMSprop(lr= 0.001),\n",
    "    loss = 'binary_crossentropy', #binary decision for each category\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 1.6771 - accuracy: 0.0833 - val_loss: 0.4735 - val_accuracy: 0.1379\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 1s 353ms/step - loss: 0.4291 - accuracy: 0.1250 - val_loss: 0.3892 - val_accuracy: 0.2759\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.3799 - accuracy: 0.2917 - val_loss: 0.4587 - val_accuracy: 0.3103\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 0.6389 - accuracy: 0.2778 - val_loss: 0.3561 - val_accuracy: 0.2414\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 0.3641 - accuracy: 0.2083 - val_loss: 0.3404 - val_accuracy: 0.2759\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 0.2982 - accuracy: 0.3750 - val_loss: 0.3838 - val_accuracy: 0.3103\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.2960 - accuracy: 0.5000 - val_loss: 0.3618 - val_accuracy: 0.2759\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 1s 353ms/step - loss: 0.3249 - accuracy: 0.2917 - val_loss: 0.3352 - val_accuracy: 0.3448\n",
      "Epoch 9/30\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3693 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_dataset,\n",
    "                     steps_per_epoch = 3,#The number of samples per gradient update for training \n",
    "                     epochs= 30,#The number of iterations over the entire dataset to train on\n",
    "                     validation_data = validation_dataset)\n",
    "#need to find a way to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "dir_path = 'Multicategory_Both_8/testing'\n",
    "for i in listdir_nohidden(dir_path):\n",
    "    img = image.load_img(dir_path+'//'+i,target_size = (200,200))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis = 0)\n",
    "    images = np.vstack([X])\n",
    "    val = model.predict(images)\n",
    "    #val is an ndarray, so argmax returns the index of the maximum value in each row (axis =1)\n",
    "    #since these are binary digits, it returns the index where the value is 1, indicating the class index\n",
    "    #there is also only one row, so it returns one value, appropriate for the if statement\n",
    "    index = (np.argmax(val, axis = 1))\n",
    "    val\n",
    "    index\n",
    "    if index == 0:\n",
    "        print(\"Bird\")\n",
    "    elif index == 1:\n",
    "        print(\"Boat\")\n",
    "    elif index == 2:\n",
    "        print(\"Car\")\n",
    "    elif index == 3:\n",
    "        print(\"Cat\")\n",
    "    elif index == 4:\n",
    "        print(\"Dog\")\n",
    "    elif index == 5:\n",
    "        print(\"Living\")\n",
    "    elif index == 6:\n",
    "        print(\"Nonliving\")\n",
    "    else:\n",
    "        print(\"Plane\")\n",
    "        \n",
    "#produces only bird/0s. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
