{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from utils import *\n",
    "#to check utils.py is working properly, run \"import utils\" and \"utils.__file__\" in a separate notebook file\n",
    "#may need to install other packages\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = pd.read_csv(\"multilabel_living_and_nonliving.csv\")\n",
    "print(\"Number of photos: {}\\n\".format(len(photos)))\n",
    "photos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label frequencies in descending order\n",
    "label_freq = photos['Labels'].apply(lambda s: str(s).split('|')).explode().value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Bar plot\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Label frequency\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Labels into a list of labels\n",
    "photos['Labels'] = photos['Labels'].apply(lambda s: [l for l in str(s).split('|')])\n",
    "photos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(photos['Image Location'], photos['Labels'], test_size=0.2, random_state=44)\n",
    "print(\"Number of photos for training: \", len(X_train))\n",
    "print(\"Number of photos for validation: \", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [os.path.join(str(f)) for f in X_train]\n",
    "X_val = [os.path.join(str(f)) for f in X_val]\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = list(y_train)\n",
    "y_val = list(y_val)\n",
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 8 # Maximum number of images to display\n",
    "ncols = 4 # Number of columns in display\n",
    "nrows = nobs//ncols # Number of rows in display\n",
    "\n",
    "style.use(\"default\")\n",
    "plt.figure(figsize=(12,4*nrows))\n",
    "for i in range(nrows*ncols):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    plt.imshow(Image.open(X_train[i]))\n",
    "    plt.title(y_train[i], size=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "#set nobs to full dataset sizes and replace train with val to check both train and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the multi-label binarizer on the training set\n",
    "print(\"Labels:\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(y_train)\n",
    "\n",
    "# Loop over all labels and show them\n",
    "N_LABELS = len(mlb.classes_)\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the targets of the training and test sets\n",
    "y_train_bin = mlb.transform(y_train)\n",
    "y_val_bin = mlb.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example of images and their binary targets\n",
    "for i in range(3):\n",
    "    print(X_train[i], y_train_bin[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    \"\"\"Function that returns a tuple of normalized image array and labels array.\n",
    "    Args:\n",
    "        filename: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train_bin)\n",
    "val_ds = create_dataset(X_val, y_val_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "#to solve SSLCertVerificationError on Mac go to the Python 3.8 (or appropriate version) folder in \n",
    "#Applications and double click on Install Certificates.command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(N_LABELS, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_ds:\n",
    "    print(model.predict(batch)[:1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "    Use probability values instead of binary predictions.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=macro_soft_f1,\n",
    "  metrics=[macro_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=create_dataset(X_val, y_val_bin))\n",
    "print('\\nTraining took {}'.format(print_time(time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses, macro_f1s, val_macro_f1s = learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Macro soft-F1 loss: %.2f\" %val_losses[-1])\n",
    "print(\"Macro F1-score: %.2f\" %val_macro_f1s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bce = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(N_LABELS, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_bce.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n",
    "    loss=tf.keras.metrics.binary_crossentropy,\n",
    "    metrics=[macro_f1])\n",
    "    \n",
    "start = time()\n",
    "history_bce = model_bce.fit(train_ds,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_data=create_dataset(X_val, y_val_bin))\n",
    "print('\\nTraining took {}'.format(print_time(time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bce_losses, model_bce_val_losses, model_bce_macro_f1s, model_bce_val_macro_f1s = learning_curves(history_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Macro soft-F1 loss: %.2f\" %model_bce_val_losses[-1])\n",
    "print(\"Macro F1-score: %.2f\" %model_bce_val_macro_f1s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all label names\n",
    "label_names = mlb.classes_\n",
    "# Performance table with the first model (macro soft-f1 loss)\n",
    "grid = perf_grid(val_ds, y_val_bin, label_names, model)\n",
    "# Performance table with the second model (binary cross-entropy loss)\n",
    "grid_bce = perf_grid(val_ds, y_val_bin, label_names, model_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum F1-score for each label when using the second model and varying the threshold\n",
    "max_perf = grid_bce.groupby(['id', 'label', 'freq'])[['f1']].max().sort_values('f1', ascending=False).reset_index()\n",
    "max_perf.rename(columns={'f1':'f1max_bce'}, inplace=True)\n",
    "max_perf.style.background_gradient(subset=['freq', 'f1max_bce'], cmap=sns.light_palette(\"lightgreen\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation between label frequency and optimal F1 with bce: %.2f\" \n",
    "          %max_perf['freq'].corr(max_perf['f1max_bce']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = max_perf.head(5)['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"default\")\n",
    "for l in top5:\n",
    "    \n",
    "    label_grid = grid.loc[grid['id']==l, ['precision','recall','f1']]\n",
    "    label_grid = label_grid.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    label_grid_bce = grid_bce.loc[grid_bce['id']==l, ['precision','recall','f1']]\n",
    "    label_grid_bce = label_grid_bce.reset_index().drop('index', axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(9,3))\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.xticks(ticks=np.arange(0,110,10), labels=np.arange(0,110,10)/100, fontsize=10)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Performance curves - Label '+str(l)+' ('+label_names[l]+')\\nMacro Soft-F1', fontsize=10)\n",
    "    label_grid.plot(ax=ax)\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.xticks(ticks=np.arange(0,110,10), labels=np.arange(0,110,10)/100, fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Performance curves - Label '+str(l)+' ('+label_names[l]+')\\nBCE', fontsize=10)\n",
    "    label_grid_bce.plot(ax=ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set with both models\n",
    "y_hat_val = model.predict(val_ds)\n",
    "y_hat_val_bce = model_bce.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"default\")\n",
    "for l in top5:\n",
    "        \n",
    "    plt.figure(figsize=(9,3))\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.xticks(ticks=np.arange(0,1.1,0.1), fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Probability distribution - Label '+str(l)+' ('+label_names[l]+')\\nMacro Soft-F1', fontsize=10)\n",
    "    plt.xlim(0,1)\n",
    "    ax = sns.distplot(y_hat_val[:,l], bins=30, kde=True, color=\"g\")\n",
    "    \n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    plt.xticks(ticks=np.arange(0,1.1,0.1), fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('Probability distribution - Label '+str(l)+' ('+label_names[l]+')\\nBCE', fontsize=10)\n",
    "    plt.xlim(0,1)\n",
    "    ax = sns.distplot(y_hat_val_bce[:,l], bins=30, kde=True, color=\"b\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(img_path):\n",
    "    \n",
    "    # Get movie info\n",
    "    #imdbId = movies.loc[movies['Title']==title]['imdbId'].iloc[0]\n",
    "    #genre = movies.loc[movies['Title']==title]['Genre'].iloc[0]\n",
    "    #img_path = os.path.join('./data/movie_poster/images', str(imdbId)+'.jpg')\n",
    "\n",
    "    # Read and prepare image\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Generate prediction\n",
    "    prediction = (model.predict(img) > 0.5).astype('int')\n",
    "    prediction = pd.Series(prediction[0])\n",
    "    prediction.index = mlb.classes_\n",
    "    prediction = prediction[prediction==1].index.values\n",
    "\n",
    "    # Dispaly image with prediction\n",
    "    style.use('default')\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(Image.open(img_path))\n",
    "    #plt.title('\\n\\n{}\\n\\nGenre\\n{}\\n\\nPrediction\\n{}\\n'.format(title, genre, list(prediction)), fontsize=9)\n",
    "    plt.title(list(prediction), fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = [\"Multicategory_Both_8/testing/A.png\",\"Multicategory_Both_8/testing/B.png\",\n",
    "          \"Multicategory_Both_8/testing/C.png\",\"Multicategory_Both_8/testing/D.png\",\n",
    "          \"Multicategory_Both_8/testing/E.png\"]\n",
    "#need to insert testing dataset here\n",
    "#could use a csv file like for training and validation dataset\n",
    "\n",
    "for t in photos:\n",
    "    show_prediction(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "export_path = \"./models/soft-f1_{}\".format(t)\n",
    "model.save(export_path) #save your model \n",
    "print(\"Model with macro soft-f1 was exported in this path: '{}'\".format(export_path))\n",
    "\n",
    "export_path_bce = \"./models/bce_{}\".format(t)\n",
    "model.save(export_path_bce) #save your model\n",
    "print(\"Model with bce was exported in this path: '{}'\".format(export_path_bce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = keras.models.load_model(export_path)\n",
    "reloaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
